# Methods-For-Comparing-Text-Similarity. Text Similarity Evaluation in Natural and Programming Languages

## Overview

This project focuses on evaluating and comparing various algorithms for measuring similarity between texts (natural language and programming one)

## Project Structure

The following markdown files contain the evaluation outputs:

### Natural Language (Ukrainian)

- NL-ExpectedTable.md — Human-annotated expected similarity scores (in percent)
- NL-SimilarityTable.md — Actual algorithm output scores
- NL-DiffTable.md — Difference between expected and actual scores
- NL-Report.md — Summary statistics

### Programming Language (Python)

- PL-ExpectedTable.md — Expected functional similarity scores for code pairs
- PL-SimilarityTable.md — Algorithm-generated similarity results
- PL-DiffTable.md — Differences between expected and calculated scores
- PL-Report.md — Summary statistics
